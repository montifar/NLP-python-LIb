{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXtSFoG+PdnBcgPNz8kexO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/montifar/NLP-python-LIb/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Download needed resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Sample Data\n",
        "data = {\n",
        "    \"text\": [\n",
        "        \"Hello, this is an example!\",\n",
        "        \"Text preprocessing is VERY important.\",\n",
        "        \"Natural language processing with Python.\"\n",
        "    ]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Initialize Tools\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def clean_text(text):\n",
        "    # Tokenize\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "\n",
        "    # Remove stopwords + non-alphabetic\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply cleaning\n",
        "df[\"cleaned_text\"] = df[\"text\"].apply(clean_text)\n",
        "\n",
        "# Vectorization\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(df[\"cleaned_text\"])\n",
        "\n",
        "# Show results\n",
        "print(\"Cleaned Text:\")\n",
        "print(df)\n",
        "print(\"\\nBag of Words (BOW) Feature Names:\")\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(\"\\nBOW Matrix:\")\n",
        "print(X.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_JQD7EJRKz9",
        "outputId": "ebe8ae45-f8dc-4abc-946e-a583779d6a4a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text:\n",
            "                                       text                  cleaned_text\n",
            "0                Hello, this is an example!                  hello exampl\n",
            "1     Text preprocessing is VERY important.        text preprocess import\n",
            "2  Natural language processing with Python.  natur languag process python\n",
            "\n",
            "Bag of Words (BOW) Feature Names:\n",
            "['exampl' 'hello' 'import' 'languag' 'natur' 'preprocess' 'process'\n",
            " 'python' 'text']\n",
            "\n",
            "BOW Matrix:\n",
            "[[1 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 1 0 0 1]\n",
            " [0 0 0 1 1 0 1 1 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}